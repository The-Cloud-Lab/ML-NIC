{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b0d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc9e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69270d86",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e015b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Data ###\n",
    "dataset = pd.read_excel(\"/home/admin2/ML_NIC/datasets/land+mines-1/Mine_Dataset.xls\", \n",
    "                        sheet_name=\"Normalized_Data\", names=['Voltage', 'Height', 'Soil Type', 'Mine Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = dataset.drop(columns=['Mine Type'])\n",
    "dataset_labels = dataset['Mine Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Train and Test Sets ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_features, dataset_labels, \n",
    "                                                    random_state=seed, test_size=0.2,\n",
    "                                                    stratify=dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfefc45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750028e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train = np.hstack((np.delete(X_train, 2, 1), one_hot.fit_transform(X_train[:, 2].reshape(-1, 1)).toarray()))\n",
    "X_test = np.hstack((np.delete(X_test, 2, 1), one_hot.transform(X_test[:, 2].reshape(-1, 1)).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d48c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up model\n",
    "with open(\"model.pkl\", 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9774f",
   "metadata": {},
   "source": [
    "# Micro-C Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181328c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "values = clf.tree_.value\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "while len(stack) > 0:\n",
    "    # `pop` ensures each node is only visited once\n",
    "    node_id, depth = stack.pop()\n",
    "    node_depth[node_id] = depth\n",
    "\n",
    "    # If the left and right child of a node is not the same we have a split\n",
    "    # node\n",
    "    is_split_node = children_left[node_id] != children_right[node_id]\n",
    "    # If a split node, append left and right children and depth to `stack`\n",
    "    # so we can loop through them\n",
    "    if is_split_node:\n",
    "        stack.append((children_left[node_id], depth + 1))\n",
    "        stack.append((children_right[node_id], depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\n",
    "    \"The binary tree structure has {n} nodes and has \"\n",
    "    \"the following tree structure:\\n\".format(n=n_nodes)\n",
    ")\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\n",
    "            \"{space}node={node} is a leaf node with value={value}.\".format(\n",
    "                space=node_depth[i] * \"\\t\", node=i, value=values[i]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"{space}node={node} is a split node with value={value}: \"\n",
    "            \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "            \"else to node {right}.\".format(\n",
    "                space=node_depth[i] * \"\\t\",\n",
    "                node=i,\n",
    "                left=children_left[i],\n",
    "                feature=feature[i],\n",
    "                threshold=threshold[i],\n",
    "                right=children_right[i],\n",
    "                value=values[i],\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcd960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide number of bits required for the path storage\n",
    "num_features = clf.n_features_in_\n",
    "classes = clf.classes_\n",
    "num_leaves = int(np.sum(is_leaves))\n",
    "num_result_words = math.ceil(num_leaves/32.0)\n",
    "result_init = hex((2**(num_leaves % 32))-1)\n",
    "features_per_result_core = int(32.0/num_result_words)\n",
    "num_result_cores = [math.ceil(num_features / features_per_result_core)]\n",
    "\n",
    "while(num_result_cores[-1] != 1):\n",
    "    num_result_cores.append(math.ceil(num_result_cores[-1] / features_per_result_core))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78240ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bits = 16\n",
    "dec_bits = 13\n",
    "\n",
    "def num_translate(number, total_bits, dec_bits): \n",
    "    return round(number * (2**dec_bits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"__lmem uint32_t path_class[] = {\", end='')\n",
    "for i in range(is_leaves.shape[0]):\n",
    "    if (is_leaves[i]):\n",
    "        print(f\"{classes[np.argmax(values[i][0])]}\", end=', ')\n",
    "print('};')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth-first search through nodes\n",
    "def depth_first(root, left, right, prediction, feature, threshold, output, feature_id, num_result_words, feat_file):\n",
    "    if (left[root] == right[root]):  # leaf node is base case\n",
    "        if (output == ''):\n",
    "            return\n",
    "        \n",
    "        if feat_file:\n",
    "            path_id = np.sum(is_leaves[:root])\n",
    "            output = output.lstrip(\"&& \")\n",
    "            output = output.rstrip(\" \")\n",
    "\n",
    "            if (num_result_words > 1):\n",
    "                result_index = num_result_words - int(path_id/32) - 1\n",
    "                path_id = path_id % 32\n",
    "                feat_file.write(f\"        if (!({output}))\\n            result_gpr[{result_index}] &= ~(1 << {path_id});\\n\")\n",
    "            else:\n",
    "                feat_file.write(f\"        if (!({output}))\\n            result_gpr &= ~(1 << {path_id});\\n\")\n",
    "            feat_file.write(\"\\n\")\n",
    "            \n",
    "        else:\n",
    "            path_id = np.sum(is_leaves[:root])\n",
    "            output = output.lstrip(\"and \")\n",
    "            output = output.rstrip(\" \")\n",
    "\n",
    "            if (num_result_words > 1):\n",
    "                result_index = num_result_words - int(path_id/32) - 1\n",
    "                path_id = path_id % 32\n",
    "                print(f\"    if (not({output})):\\n        result_gpr[{result_index}] &= ~(1 << {path_id})\")\n",
    "            else:\n",
    "                print(f\"    if (not({output})):\\n        result_gpr &= ~(1 << {path_id})\")\n",
    "            print(\"\")\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if feat_file:\n",
    "            net_threshold = num_translate(threshold[root], total_bits, dec_bits)\n",
    "            if (feature[root] == feature_id):\n",
    "                left_output = output + f\"&& feature <= {net_threshold} \"\n",
    "                right_output = output + f\"&& feature > {net_threshold} \"\n",
    "            else:\n",
    "                left_output = output\n",
    "                right_output = output\n",
    "\n",
    "            depth_first(left[root], left, right, prediction, feature, threshold, \n",
    "                        left_output, feature_id, num_result_words, feat_file)\n",
    "            depth_first(right[root], left, right, prediction, feature, threshold, \n",
    "                        right_output, feature_id, num_result_words, feat_file)\n",
    "            \n",
    "        else:\n",
    "            net_threshold = num_translate(threshold[root], total_bits, dec_bits)\n",
    "            if (feature[root] == feature_id):\n",
    "                left_output = output + f\"and feature <= {net_threshold} \"\n",
    "                right_output = output + f\"and feature > {net_threshold} \"\n",
    "            else:\n",
    "                left_output = output\n",
    "                right_output = output\n",
    "\n",
    "            depth_first(left[root], left, right, prediction, feature, threshold, \n",
    "                        left_output, feature_id, num_result_words, feat_file)\n",
    "            depth_first(right[root], left, right, prediction, feature, threshold, \n",
    "                        right_output, feature_id, num_result_words, feat_file)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d32021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feat_id in range(num_features):\n",
    "    print(f\"def feature{feat_id+1}(feature):\")\n",
    "    \n",
    "    if (num_result_words > 1):\n",
    "        print(f\"    result_gpr = [{result_init}\", end='')\n",
    "        for i in range(1, num_result_words):\n",
    "            print(\", 0xffffffff\", end='')\n",
    "        print(']')\n",
    "    else:\n",
    "        print(f\"    result_gpr = {result_init}\")\n",
    "        \n",
    "    depth_first(0, children_left, children_right, values, feature, threshold, \"\", feat_id, num_result_words, None)\n",
    "    print(\"    return result_gpr\")\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
