{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe056fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f29560",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f995a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"/home/admin2/ML_NIC/datasets/statlog+landsat+satellite/sat.trn\", header=None,\n",
    "                           sep=' ')\n",
    "test_dataset = pd.read_csv(\"/home/admin2/ML_NIC/datasets/statlog+landsat+satellite/sat.tst\", header=None,\n",
    "                          sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e7c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.drop(columns=[36])\n",
    "train_labels = train_dataset[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9dd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_dataset.drop(columns=[36])\n",
    "test_labels = test_dataset[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944dde10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_scaler = MinMaxScaler(feature_range=(0, 1), clip=True)\n",
    "train_features = dataset_scaler.fit_transform(train_features)\n",
    "test_features = dataset_scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90fc058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up model\n",
    "with open(\"model.pkl\", 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38896c90",
   "metadata": {},
   "source": [
    "# Build Micro-C Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2730124",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "values = clf.tree_.value\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "while len(stack) > 0:\n",
    "    # `pop` ensures each node is only visited once\n",
    "    node_id, depth = stack.pop()\n",
    "    node_depth[node_id] = depth\n",
    "\n",
    "    # If the left and right child of a node is not the same we have a split\n",
    "    # node\n",
    "    is_split_node = children_left[node_id] != children_right[node_id]\n",
    "    # If a split node, append left and right children and depth to `stack`\n",
    "    # so we can loop through them\n",
    "    if is_split_node:\n",
    "        stack.append((children_left[node_id], depth + 1))\n",
    "        stack.append((children_right[node_id], depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\n",
    "    \"The binary tree structure has {n} nodes and has \"\n",
    "    \"the following tree structure:\\n\".format(n=n_nodes)\n",
    ")\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\n",
    "            \"{space}node={node} is a leaf node with value={value}.\".format(\n",
    "                space=node_depth[i] * \"\\t\", node=i, value=values[i]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"{space}node={node} is a split node with value={value}: \"\n",
    "            \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "            \"else to node {right}.\".format(\n",
    "                space=node_depth[i] * \"\\t\",\n",
    "                node=i,\n",
    "                left=children_left[i],\n",
    "                feature=feature[i],\n",
    "                threshold=threshold[i],\n",
    "                right=children_right[i],\n",
    "                value=values[i],\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cff42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide number of bits required for the path storage\n",
    "num_features = clf.n_features_in_\n",
    "classes = clf.classes_\n",
    "num_leaves = int(np.sum(is_leaves))\n",
    "num_result_words = math.ceil(num_leaves/32.0)\n",
    "result_init = hex((2**(num_leaves % 33))-1)\n",
    "features_per_result_core = int(32.0/num_result_words)\n",
    "num_result_cores = [math.ceil(num_features / features_per_result_core)]\n",
    "\n",
    "while(num_result_cores[-1] != 1):\n",
    "    num_result_cores.append(math.ceil(num_result_cores[-1] / features_per_result_core))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c1da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bits = 16\n",
    "dec_bits = 13\n",
    "\n",
    "def num_translate(number, total_bits, dec_bits):\n",
    "    ret = round(number * (2**dec_bits))\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"__lmem uint32_t path_class[] = {\", end='')\n",
    "for i in range(is_leaves.shape[0]):\n",
    "    if (is_leaves[i]):\n",
    "        print(f\"{classes[np.argmax(values[i][0])]}\", end=', ')\n",
    "print('};')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faea958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth-first search through nodes\n",
    "def depth_first(root, left, right, prediction, feature, threshold, output, feature_id, num_result_words, feat_file):\n",
    "    if (left[root] == right[root]):  # leaf node is base case\n",
    "        if (output == ''):\n",
    "            return\n",
    "        \n",
    "        if feat_file:\n",
    "            path_id = np.sum(is_leaves[:root])\n",
    "            output = output.lstrip(\"&& \")\n",
    "            output = output.rstrip(\" \")\n",
    "\n",
    "            if (num_result_words > 1):\n",
    "                result_index = num_result_words - int(path_id/32) - 1\n",
    "                path_id = path_id % 32\n",
    "                feat_file.write(f\"        if (!({output}))\\n            result_gpr[{result_index}] &= ~(1 << {path_id});\\n\")\n",
    "            else:\n",
    "                feat_file.write(f\"        if (!({output}))\\n            result_gpr &= ~(1 << {path_id});\\n\")\n",
    "            feat_file.write(\"\\n\")\n",
    "            \n",
    "        else:\n",
    "            path_id = np.sum(is_leaves[:root])\n",
    "            output = output.lstrip(\"and \")\n",
    "            output = output.rstrip(\" \")\n",
    "\n",
    "            if (num_result_words > 1):\n",
    "                result_index = num_result_words - int(path_id/32) - 1\n",
    "                path_id = path_id % 32\n",
    "                print(f\"    if (not({output})):\\n        result_gpr[{result_index}] &= ~(1 << {path_id})\")\n",
    "            else:\n",
    "                print(f\"    if (not({output})):\\n        result_gpr &= ~(1 << {path_id})\")\n",
    "            print(\"\")\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if feat_file:\n",
    "            net_threshold = num_translate(threshold[root], total_bits, dec_bits)\n",
    "            if (feature[root] == feature_id):\n",
    "                left_output = output + f\"&& feature <= {net_threshold} \"\n",
    "                right_output = output + f\"&& feature > {net_threshold} \"\n",
    "            else:\n",
    "                left_output = output\n",
    "                right_output = output\n",
    "\n",
    "            depth_first(left[root], left, right, prediction, feature, threshold, \n",
    "                        left_output, feature_id, num_result_words, feat_file)\n",
    "            depth_first(right[root], left, right, prediction, feature, threshold, \n",
    "                        right_output, feature_id, num_result_words, feat_file)\n",
    "            \n",
    "        else:\n",
    "            net_threshold = num_translate(threshold[root], total_bits, dec_bits)\n",
    "            if (feature[root] == feature_id):\n",
    "                left_output = output + f\"and feature <= {net_threshold} \"\n",
    "                right_output = output + f\"and feature > {net_threshold} \"\n",
    "            else:\n",
    "                left_output = output\n",
    "                right_output = output\n",
    "\n",
    "            depth_first(left[root], left, right, prediction, feature, threshold, \n",
    "                        left_output, feature_id, num_result_words, feat_file)\n",
    "            depth_first(right[root], left, right, prediction, feature, threshold, \n",
    "                        right_output, feature_id, num_result_words, feat_file)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat_id in range(num_features):\n",
    "    print(f\"def feature{feat_id+1}(feature):\")\n",
    "    \n",
    "    if (num_result_words > 1):\n",
    "        print(\"    result_gpr = [0xffffffff\", end='')\n",
    "        for i in range(1, num_result_words):\n",
    "            print(\", 0xffffffff\", end='')\n",
    "        print(']')\n",
    "    else:\n",
    "        print(f\"    result_gpr = {result_init}\")\n",
    "        \n",
    "    depth_first(0, children_left, children_right, values, feature, threshold, \"\", feat_id, num_result_words, None)\n",
    "    print(\"    return result_gpr\")\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
