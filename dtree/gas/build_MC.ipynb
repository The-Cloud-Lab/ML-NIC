{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dafc765",
   "metadata": {},
   "source": [
    "# Build/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch1.dat\", \n",
    "                    header=None, sep=' \\d+:')\n",
    "\n",
    "batch2 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch2.dat\", \n",
    "                    header=None, sep=' \\d+:')\n",
    "\n",
    "batch3 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch3.dat\", \n",
    "                    header=None, sep=' \\d+:')\n",
    "\n",
    "batch4 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch4.dat\", \n",
    "                    header=None, sep=' \\d+:')\n",
    "\n",
    "batch5 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch5.dat\", \n",
    "                    header=None, sep=' \\d+:')\n",
    "\n",
    "batch6 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch6.dat\", \n",
    "                    header=None, sep=' \\d+:')\n",
    "\n",
    "batch7 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch7.dat\", \n",
    "                    header=None, sep=' \\d+:')\n",
    "\n",
    "batch8 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch8.dat\", \n",
    "                    header=None, sep=' \\d+:')\n",
    "\n",
    "batch9 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch9.dat\", \n",
    "                    header=None, sep=' \\d+:')\n",
    "\n",
    "batch10 = pd.read_csv(\"/home/admin2/ML_NIC/datasets/gas+sensor+array+drift+dataset/batch10.dat\", \n",
    "                    header=None, sep=' \\d+:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c214c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([batch1, batch2, batch3, batch4, batch5,\n",
    "                    batch6, batch7, batch8, batch9, batch10], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9407c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.drop(columns=[0])\n",
    "labels = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8503485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=seed,\n",
    "                                                   stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df243574",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler(feature_range=(0, 1), clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2bcab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = minmax.fit_transform(X_train)\n",
    "X_test = minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up model\n",
    "with open(\"model.pkl\", 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686e9b8",
   "metadata": {},
   "source": [
    "# Micro-C Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "values = clf.tree_.value\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "while len(stack) > 0:\n",
    "    # `pop` ensures each node is only visited once\n",
    "    node_id, depth = stack.pop()\n",
    "    node_depth[node_id] = depth\n",
    "\n",
    "    # If the left and right child of a node is not the same we have a split\n",
    "    # node\n",
    "    is_split_node = children_left[node_id] != children_right[node_id]\n",
    "    # If a split node, append left and right children and depth to `stack`\n",
    "    # so we can loop through them\n",
    "    if is_split_node:\n",
    "        stack.append((children_left[node_id], depth + 1))\n",
    "        stack.append((children_right[node_id], depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\n",
    "    \"The binary tree structure has {n} nodes and has \"\n",
    "    \"the following tree structure:\\n\".format(n=n_nodes)\n",
    ")\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\n",
    "            \"{space}node={node} is a leaf node with value={value}.\".format(\n",
    "                space=node_depth[i] * \"\\t\", node=i, value=values[i]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"{space}node={node} is a split node with value={value}: \"\n",
    "            \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "            \"else to node {right}.\".format(\n",
    "                space=node_depth[i] * \"\\t\",\n",
    "                node=i,\n",
    "                left=children_left[i],\n",
    "                feature=feature[i],\n",
    "                threshold=threshold[i],\n",
    "                right=children_right[i],\n",
    "                value=values[i],\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b26dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide number of bits required for the path storage\n",
    "num_features = clf.n_features_in_\n",
    "classes = clf.classes_\n",
    "num_leaves = int(np.sum(is_leaves))\n",
    "num_result_words = math.ceil(num_leaves/32.0)\n",
    "result_init = hex((2**(num_leaves % 33))-1)\n",
    "features_per_result_core = int(32.0/num_result_words)\n",
    "num_result_cores = [math.ceil(num_features / features_per_result_core)]\n",
    "\n",
    "while(num_result_cores[-1] != 1):\n",
    "    num_result_cores.append(math.ceil(num_result_cores[-1] / features_per_result_core))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001808f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bits = 16\n",
    "dec_bits = 13\n",
    "\n",
    "def num_translate(number, total_bits, dec_bits):\n",
    "    return round(number * (2**dec_bits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"__lmem uint32_t path_class[] = {\", end='')\n",
    "for i in range(is_leaves.shape[0]):\n",
    "    if (is_leaves[i]):\n",
    "        print(f\"{classes[np.argmax(values[i][0])]}\", end=', ')\n",
    "print('};')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec846234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth-first search through nodes\n",
    "def depth_first(root, left, right, prediction, feature, threshold, output, feature_id, num_result_words, feat_file):\n",
    "    if (left[root] == right[root]):  # leaf node is base case\n",
    "        if (output == ''):\n",
    "            return\n",
    "        \n",
    "        if feat_file:\n",
    "            path_id = np.sum(is_leaves[:root])\n",
    "            output = output.lstrip(\"&& \")\n",
    "            output = output.rstrip(\" \")\n",
    "\n",
    "            if (num_result_words > 1):\n",
    "                result_index = num_result_words - int(path_id/32) - 1\n",
    "                path_id = path_id % 32\n",
    "                feat_file.write(f\"        if (!({output}))\\n            result_gpr[{result_index}] &= ~(1 << {path_id});\\n\")\n",
    "            else:\n",
    "                feat_file.write(f\"        if (!({output}))\\n            result_gpr &= ~(1 << {path_id});\\n\")\n",
    "            feat_file.write(\"\\n\")\n",
    "            \n",
    "        else:\n",
    "            path_id = np.sum(is_leaves[:root])\n",
    "            output = output.lstrip(\"and \")\n",
    "            output = output.rstrip(\" \")\n",
    "\n",
    "            if (num_result_words > 1):\n",
    "                result_index = num_result_words - int(path_id/32) - 1\n",
    "                path_id = path_id % 32\n",
    "                print(f\"    if (not({output})):\\n        result_gpr[{result_index}] &= ~(1 << {path_id})\")\n",
    "            else:\n",
    "                print(f\"    if (not({output})):\\n        result_gpr &= ~(1 << {path_id})\")\n",
    "            print(\"\")\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if feat_file:\n",
    "            net_threshold = num_translate(threshold[root], total_bits, dec_bits)\n",
    "            if (feature[root] == feature_id):\n",
    "                left_output = output + f\"&& feature <= {net_threshold} \"\n",
    "                right_output = output + f\"&& feature > {net_threshold} \"\n",
    "            else:\n",
    "                left_output = output\n",
    "                right_output = output\n",
    "\n",
    "            depth_first(left[root], left, right, prediction, feature, threshold, \n",
    "                        left_output, feature_id, num_result_words, feat_file)\n",
    "            depth_first(right[root], left, right, prediction, feature, threshold, \n",
    "                        right_output, feature_id, num_result_words, feat_file)\n",
    "            \n",
    "        else:\n",
    "            net_threshold = num_translate(threshold[root], total_bits, dec_bits)\n",
    "            if (feature[root] == feature_id):\n",
    "                left_output = output + f\"and feature <= {net_threshold} \"\n",
    "                right_output = output + f\"and feature > {net_threshold} \"\n",
    "            else:\n",
    "                left_output = output\n",
    "                right_output = output\n",
    "\n",
    "            depth_first(left[root], left, right, prediction, feature, threshold, \n",
    "                        left_output, feature_id, num_result_words, feat_file)\n",
    "            depth_first(right[root], left, right, prediction, feature, threshold, \n",
    "                        right_output, feature_id, num_result_words, feat_file)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce65a7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feat_id in range(num_features):    \n",
    "    print(f\"def feature{feat_id+1}(feature):\")\n",
    "    \n",
    "    if (num_result_words > 1):\n",
    "        print(\"    result_gpr = [0xffffffff\", end='')\n",
    "        for i in range(1, num_result_words):\n",
    "            print(\", 0xffffffff\", end='')\n",
    "        print(']')\n",
    "    else:\n",
    "        print(f\"    result_gpr = {result_init}\")\n",
    "        \n",
    "    depth_first(0, children_left, children_right, values, feature, threshold, \"\", feat_id, num_result_words, None)\n",
    "    print(\"    return result_gpr\")\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
